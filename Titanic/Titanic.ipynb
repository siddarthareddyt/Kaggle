{
  "cells": [
    {
      "metadata": {
        "scrolled": true,
        "collapsed": true,
        "_uuid": "a0893ed1c9d36a84e0d93611674ca649337478f0",
        "_cell_guid": "529887d6-c525-49bf-bd1b-758b33529372",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport sklearn.feature_selection\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import ShuffleSplit\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn import tree\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\",\".\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "22a694f943fdc07b24dbea6815b6091c7e4509a2",
        "collapsed": true,
        "_cell_guid": "02dc1fd8-70db-406c-aae7-eb5b5dee8c16",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train.csv\")\nholdout = pd.read_csv(\"../input/test.csv\")\n\n#no. of null embed columns\ntrain.isnull().sum()\n\n#some stats of the datasets\ntrain.describe()\nholdout.describe()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "85a35a923e585b1ae3084c8b2b833aa1f3b09fe3",
        "collapsed": true,
        "_cell_guid": "2315660c-9ffc-4dec-ad46-c65f3741cb98",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#data exploration\n\n#survival vs gender indicates females have more chances of surviving\ngender_pivot = train.pivot_table(index=\"Sex\",values=\"Survived\")\ngender_pivot.plot.bar()\nplt.show()\n\n\n#pclass vs survived indicates class 1 and class 2 people are more likely to survive\nclass_pivot = train.pivot_table(index=\"Pclass\", values=\"Survived\")\nclass_pivot.plot.bar()\nplt.show()\n\n#Family size vs survived\nfamily_cols = [\"SibSp\",\"Parch\",\"Survived\"]\nfamily = train[family_cols].copy()\nfamily['familysize'] = family[[\"SibSp\",\"Parch\"]].sum(axis=1)\nfamilySize = family[[\"SibSp\",\"Parch\"]].sum(axis=1)\nfamily[\"isalone\"] = np.where(familySize>=1, 1, 0)\nfamily_pivot = family.pivot_table(index=\"familysize\",values=\"Survived\")\nisalone_pivot = family.pivot_table(index=\"isalone\", values=\"Survived\")\nisalone_pivot.plot.bar(ylim=(0,1),yticks=np.arange(0,1,.1))\nfamily_pivot.plot.bar(ylim=(0,1),yticks=np.arange(0,1,.1))\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fcf89e5c7fe989fd78dc08f15fe842a87f3bf944",
        "collapsed": true,
        "_cell_guid": "c66ecde5-d573-4e6d-aff7-bc893ce6c32d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#data preprocessing\ntrain[\"Fare\"] = train[\"Fare\"].fillna(train[\"Fare\"].mean())\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n\nholdout[\"Fare\"] = holdout[\"Fare\"].fillna(train[\"Fare\"].mean())\nholdout[\"Embarked\"] = holdout[\"Embarked\"].fillna(\"S\")\n\ntrain[\"Age\"] = train[\"Age\"].fillna(-0.5)\nholdout[\"Age\"] = holdout[\"Age\"].fillna(-0.5)\n\ntrain.head(2)\nholdout.head(2)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8ed71b99db2092b215e64b5d3bd62d8ee69551bc",
        "collapsed": true,
        "_cell_guid": "c09f9431-3117-4c46-ab24-8b0adae8a7e4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#feature engineering\n\n#categorize age\ncuts = [-1,0,5,12,18,35,60,100]\nlabels = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\ntrain[\"Age_categories\"] = pd.cut(train[\"Age\"],cuts,labels=labels)\nholdout[\"Age_categories\"] = pd.cut(holdout[\"Age\"],cuts,labels=labels)\n\n#categorize fare\nfare_cuts = [-1,12,50,100,1000]\nfare_labels = [\"0-12\",\"12-50\",\"50-100\",\"100+\"]\ntrain[\"Fare_categories\"] = pd.cut(train[\"Fare\"],fare_cuts,labels=fare_labels)\nholdout[\"Fare_categories\"] = pd.cut(holdout[\"Fare\"],fare_cuts,labels=fare_labels)\n\n\n#categorize cabin types\n\ntrain[\"Cabin_type\"] = train[\"Cabin\"].str[0]\ntrain[\"Cabin_type\"] = train[\"Cabin_type\"].fillna(\"Unknown\")\ntrain = train.drop('Cabin',axis=1)\n\nholdout[\"Cabin_type\"] = holdout[\"Cabin\"].str[0]\nholdout[\"Cabin_type\"] = holdout[\"Cabin_type\"].fillna(\"Unknown\")\nholdout = holdout.drop('Cabin',axis=1)\n\n#engineer Title feature\ntitles = {\n        \"Mr\" :         \"Mr\",\n        \"Mme\":         \"Mrs\",\n        \"Ms\":          \"Mrs\",\n        \"Mrs\" :        \"Mrs\",\n        \"Master\" :     \"Master\",\n        \"Mlle\":        \"Miss\",\n        \"Miss\" :       \"Miss\",\n        \"Capt\":        \"Officer\",\n        \"Col\":         \"Officer\",\n        \"Major\":       \"Officer\",\n        \"Dr\":          \"Officer\",\n        \"Rev\":         \"Officer\",\n        \"Jonkheer\":    \"Royalty\",\n        \"Don\":         \"Royalty\",\n        \"Sir\" :        \"Royalty\",\n        \"Countess\":    \"Royalty\",\n        \"Dona\":        \"Royalty\",\n        \"Lady\" :       \"Royalty\"\n    }\ntrain_titles = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\ntrain[\"Title\"] = train_titles.map(titles)\n\nholdout_titles = holdout[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\nholdout[\"Title\"] = holdout_titles.map(titles)\n\n#engineer isalone\nfamilySize_train = train[[\"SibSp\",\"Parch\"]].sum(axis=1)\ntrain[\"isalone\"] = np.where(familySize_train>=1, 1, 0)\n\nfamilySize_holdout = holdout[[\"SibSp\",\"Parch\"]].sum(axis=1)\nholdout[\"isalone\"] = np.where(familySize_holdout>=1, 1, 0)\n\n\n#dummy variables for all the categorical features\ndef get_dummies(df, column_name):\n    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n    df = pd.concat([df,dummies],axis=1)\n    return df\n\ncolumnNames = [\"Age_categories\", \"Pclass\", \"Sex\", \"Fare_categories\", \"Title\", \"Cabin_type\", \"Embarked\"]\n\nfor column in columnNames:\n    dummies_train = pd.get_dummies(train[column],prefix=column)\n    train = pd.concat([train,dummies_train],axis=1)\n    \n    dummies_holdout = pd.get_dummies(holdout[column],prefix=column)\n    holdout = pd.concat([holdout,dummies_holdout],axis=1)\n    \ntrain.head(5)\nholdout.head(5)\n\nprint(holdout.columns)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "40bc1239d7717ca2a3521c015f33637d49eb9b7d",
        "collapsed": true,
        "_cell_guid": "b8ebb01e-9e82-4aac-9d93-30e6466a24fa",
        "trusted": false
      },
      "cell_type": "code",
      "source": "columns = ['Age_categories_Missing', 'Age_categories_Infant',\n       'Age_categories_Child', 'Age_categories_Teenager',\n       'Age_categories_Young Adult', 'Age_categories_Adult',\n       'Age_categories_Senior', 'Pclass_1', 'Pclass_2', 'Pclass_3',\n       'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n       'Fare_categories_0-12',\n       'Fare_categories_12-50','Fare_categories_50-100', 'Fare_categories_100+',\n       'Title_Master', 'Title_Miss', 'Title_Mr','Title_Mrs', 'Title_Officer',\n       'Title_Royalty', 'Cabin_type_A','Cabin_type_B', 'Cabin_type_C', 'Cabin_type_D',\n       'Cabin_type_E','Cabin_type_F', 'Cabin_type_G', 'Cabin_type_Unknown', 'isalone']\n\n#model-selection\ndef get_model(df, features):\n    \n    train_X = df[features]\n    train_y = df[\"Survived\"]\n    \n    cv = ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0)\n    model_params = [\n            {\n                    \"name\": \"RandomForestClassifier\",\n                    \"estimator\": RandomForestClassifier(random_state=0),\n                    \"hyperparameters\":\n                        {\n                                \"n_estimators\": [20,25, 35, 40,45, 50, 55, 60, 65, 70, 75],\n                                \"criterion\": [\"entropy\", \"gini\"],\n                                \"max_features\": [\"log2\", \"sqrt\"],\n                                \"min_samples_leaf\": [1, 5, 8],\n                                \"min_samples_split\": [2, 3, 5]\n                        }\n            },\n            {\n                    \"name\": \"DecisionTreeClassifier\",\n                    \"estimator\": tree.DecisionTreeClassifier(),\n                    \"hyperparameters\":\n                        {\n                                \"criterion\": [\"entropy\", \"gini\"],\n                                \"max_depth\": [None, 2,4,6,8,10, 12, 14, 16],\n                                'min_samples_split': [2,3,4,5,10,.03,.05,.1],\n                                \"max_features\": [None, \"auto\"],\n                                \"min_samples_leaf\": [1,2,3,4,5,10,12, .5, .03,.05,.1]\n                        }\n            },\n            {\n                    \"name\": \"KernelSVMClassifier\",\n                    \"estimator\": SVC(random_state=0),\n                    \"hyperparameters\":\n                        {\n                                \"kernel\": [\"rbf\"],\n                                \"C\": np.logspace(-9, 3, 13),\n                                \"gamma\": np.logspace(-9, 3, 13)\n                        }\n            } ,\n            {\n                    \"name\": \"KNeighborsClassifier\",\n                    \"estimator\": KNeighborsClassifier(),\n                    \"hyperparameters\":\n                        {\n                                \"n_neighbors\": range(1,20,2),\n                                \"weights\": [\"distance\", \"uniform\"],\n                                \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n                                \"p\": [1,2]\n                        }\n            },\n            {\n                    \"name\": \"LogisticRegressionClassifier\",\n                    \"estimator\": LogisticRegression(),\n                    \"hyperparameters\":\n                        {\n                                \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n                        }\n            }          \n            ]\n    models = []\n    for model in model_params:\n        print(model[\"name\"])\n        grid = GridSearchCV(model[\"estimator\"], \n                            param_grid=model[\"hyperparameters\"], \n                            cv=10)\n        grid.fit(train_X, train_y)\n        \n        model_att = {\n                \"model\": grid.best_estimator_, \n                \"best_params\": grid.best_params_, \n                \"best_score\": grid.best_score_,\n                \"grid\": grid\n                }\n        models.append(model_att)\n        print(\"Evaluated model and its params: \")\n        print(grid.best_params_)\n        print(grid.best_score_)\n    return models\n\n#Artificial Neural Network\ndef ann_model(df, features):\n    classifier = Sequential()\n    classifier.add(Dense(input_dim=len(features), units=15, activation=\"relu\", kernel_initializer=\"uniform\"))\n    \n    classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    \n    train_X = df[features]\n    train_y = df[\"Survived\"]\n    classifier.fit(np.array(train_X), np.array(train_y), batch_size = 10, epochs = 100)\n    return classifier\n\n#feature selection using RFECV\ndef get_features(df, columns, model=None):\n    newDf = df.copy()\n    newDf = newDf.select_dtypes(['number'])\n    newDf = newDf.dropna(axis=1, how='any')\n    \n    #dropColumns = [\"PassengerId\", \"Survived\"]\n    #newDf = newDf.drop(dropColumns, axis = 1)\n    \n    all_X = newDf[columns]\n    all_y = df[\"Survived\"]\n    \n    cv = StratifiedShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0)\n    if model == None:\n        classifier = tree.DecisionTreeClassifier(\n                criterion=\"entropy\",\n                max_depth=10,\n                max_features='auto',\n                max_leaf_nodes=None,\n                min_impurity_decrease = 0.0,\n                min_samples_leaf = 10,\n                min_samples_split = 3\n                )\n    else:\n        classifier = model\n    selector = RFECV(classifier, scoring = 'roc_auc', cv=cv, step = 1)\n    selector.fit(all_X,all_y)\n    rfecv_columns = all_X.columns[selector.support_]\n    return rfecv_columns\n\nmodels = get_model(train, columns)\n\n#select the best one based on its index from console\nbest_grid = models[0][\"grid\"]\nbest_classifier = models[0][\"model\"]\nbest_params = models[0][\"best_params\"]\n\nrfecv_features = get_features(train, columns, best_classifier)\nprint(len(rfecv_features))\nprint(rfecv_features)\n\nmodels = get_model(train, rfecv_features)\nbest_classifier = models[0][\"model\"]\n\npredictions = best_classifier.predict(holdout[rfecv_features])\n\nsub = {\"PassengerId\": holdout[\"PassengerId\"], \"Survived\": predictions}\nsubmission = pd.DataFrame(sub)\nsubmission.to_csv(path_or_buf=\"Submission.csv\", index=False, header=True)\n\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "file_extension": ".py",
      "nbconvert_exporter": "python",
      "mimetype": "text/x-python",
      "version": "3.6.3",
      "pygments_lexer": "ipython3",
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}