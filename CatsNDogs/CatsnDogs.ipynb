{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "3efc73da-2605-4389-96da-7e30cc939d1a",
        "_uuid": "733e2fc4797187f0d88f6809304a1f35bea2d4ce"
      },
      "cell_type": "markdown",
      "source": "**Classfication of Cats and Dogs with Keras (Tensoflow backend)**\n\nHere we shall use, the data set provided by [Kaggle](https://www.kaggle.com/c/dogs-vs-cats). I have segregated the given dataset into a structure containing different sets for training and validation.\n\nDirectory structure:\n\ndataset/\n\n    training_set/\n    \n        cats/\n        \n        dogs/\n        \n    test_set/\n    \n        cats/\n        \n        dogs/\n        \n    This notebook generates a CNN model for image recognition task and saves it."
    },
    {
      "metadata": {
        "_cell_guid": "2b74039e-0491-42da-9c2f-8737b34b8bb2",
        "_uuid": "759d15eaffa37c73de6ff4379049acb2710aced2",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense, Dropout\n#print(check_output([\"ls\", \"../input/dataset/dataset/training_set/cats\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ad01082b-d197-4a91-8a4b-643a49ebee11",
        "_uuid": "0b60839b8cac9692ad83232a4a23fcf02c9d82d2"
      },
      "cell_type": "markdown",
      "source": "First, lets declare the parameters width and height of the image we would like to transform our images to. \nI have taken 60 as it generates less number of units in convolution layers and hence requires less time to fit model."
    },
    {
      "metadata": {
        "_cell_guid": "40f5ca42-796c-4544-85a3-ef34cdeda7c4",
        "_uuid": "8473a18fad81693199a9eebd167ab7c35bf761e9",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "shape_w = 60\nshape_h = 60\nbatchsize = 32",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1cee82df-1ac9-49bb-b499-ba0f756a9de0",
        "_uuid": "25f149f8f7a04338c27f509f08606cc7f70352c3"
      },
      "cell_type": "markdown",
      "source": "Now, declare a sequential Neural network and add three convolution layers to it.\nHere I have used 32 filters each 3*3 matrix in the first 2 layers and 64 filters in the last conv layer."
    },
    {
      "metadata": {
        "_cell_guid": "06f36b23-b7b2-49f6-81f9-a5468ec43c93",
        "_uuid": "6b5165f0e219a862386f62d3abbf7421ebefe7eb",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "classifier = Sequential()\n\nclassifier.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(shape_w, shape_h, 3)))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\nclassifier.add(Conv2D(32, (3, 3), activation=\"relu\"))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\nclassifier.add(Conv2D(64, (3, 3), activation=\"relu\"))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "16ba0d00-0f3b-41f5-871a-263c7981d325",
        "_uuid": "5579c21f3d6ad5f043e967cc4d0c2d337454dd88"
      },
      "cell_type": "markdown",
      "source": "Now, we have to flatten the matrices to a single dimensional vector for the fully connected network"
    },
    {
      "metadata": {
        "_cell_guid": "22937188-3339-494f-9e86-8c3cca56b476",
        "_uuid": "b13a8445bddd63405e27734226f6d5441808f80b",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "classifier.add(Flatten())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "87d2ee13-7405-441c-b14a-f6f9077ed5bb",
        "_uuid": "58db8c429fd7d7cd387767f16529f1c5f00f6c01"
      },
      "cell_type": "markdown",
      "source": "Adding a fully connected network with 1 hidden layer and dropout of 0.5, which tries to prevent model-overfitting."
    },
    {
      "metadata": {
        "_cell_guid": "a152114a-730d-455b-8a2c-5d060cb9d805",
        "_uuid": "df97663ccf3d4e0ca7c4c274595d4b37994c4812",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "classifier.add(Dense(units=128, activation=\"relu\"))\nclassifier.add(Dropout(0.5))\nclassifier.add(Dense(units=1, activation=\"sigmoid\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "98524490-2aea-4152-a530-58bebbcceb37",
        "_uuid": "89f9fa9d4d810537bff35f63d54a36978f1dd5b9"
      },
      "cell_type": "markdown",
      "source": "Compile the model with 'adam' optimizer'"
    },
    {
      "metadata": {
        "_cell_guid": "4b9fbaad-133d-4b69-9bb9-df562a157c81",
        "_uuid": "5314ea5db1f95d85a88fa9b9c6a8c3852e699f05",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "2dd34128-5f5e-4bcd-8d15-d025f0acf46b",
        "_uuid": "5841515b1e9b3f346b2f365cf5c9e7b6b58d8703"
      },
      "cell_type": "markdown",
      "source": "**Generate image data from ImageDataGenerator**\nThis helps in training the model on more images from a small set of training images. This can be used to prevent model-overfitting by generating various images with transformations."
    },
    {
      "metadata": {
        "_cell_guid": "07c95e93-23db-4fa6-9ef7-239aebc1fe9b",
        "_uuid": "314bd683c04a0d2839c9ecad854e9c2e69e1c323",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\nvalidation_datagen = ImageDataGenerator(rescale = 1./255)\n\ntraining_set = train_datagen.flow_from_directory('../input/dataset/dataset/training_set',\n                                                 target_size = (shape_w, shape_h),\n                                                 batch_size = batchsize,\n                                                 class_mode = 'binary')\n\nvalidation_set = validation_datagen.flow_from_directory('../input/dataset/dataset/test_set',\n                                            target_size = (shape_w, shape_h),\n                                            batch_size = batchsize,\n                                            class_mode = 'binary')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ffe940db-2c2b-40c9-9a54-f4239253b6c9",
        "_uuid": "a8a898c2869a7e6145fd417739601e5daca6929d"
      },
      "cell_type": "markdown",
      "source": "**Fit the model and save**"
    },
    {
      "metadata": {
        "_cell_guid": "065229d7-e84e-4537-808a-90c6e4173ca4",
        "_uuid": "2dbf36cfabaf29a69f4178fad3023885bf87a300",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "classifier.fit_generator(training_set,\n                         steps_per_epoch = (10000 // batchsize),\n                         epochs = 50,\n                         validation_data = validation_set,\n                         validation_steps = (2500 // batchsize))\n\nclassifier.save('catsdogs.h5')\nclassifier.save_weights('catsdogs_weights.h5')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}