{
  "cells": [
    {
      "metadata": {
        "_uuid": "15a8bf621dc534b61bf774f954b1f4fb0b373535",
        "_cell_guid": "25efa0dd-3906-479d-a92e-df153bd1739f"
      },
      "cell_type": "markdown",
      "source": "**Load all the relevant libraries**"
    },
    {
      "metadata": {
        "_uuid": "af8664ef7f0b76b5cde5b69cd008b0f24c8afb62",
        "collapsed": true,
        "_cell_guid": "9d819aa0-9ea5-4e10-bbb9-729571c8ebc9",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "de029c92426c907d5ffe82218e4d0347400de54d",
        "collapsed": true,
        "_cell_guid": "6ff80f8e-5ae4-4182-9e19-2374cf1ebe4b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train.csv\")\nholdout = pd.read_csv(\"../input/test.csv\")\n\n#sale price starts at 34k till 755k with a mean of 180k. \ntrain['SalePrice'].describe()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "965484f2ddeba5dc83eaf852dd825a4f2531cb66",
        "_cell_guid": "2b0a4a26-f223-47b6-babc-74bb8c322eeb"
      },
      "cell_type": "markdown",
      "source": "**Plot a correlation matrix to identify the most correlated features to the target variable**"
    },
    {
      "metadata": {
        "_uuid": "131363cd037914b559e9177053a9782e4f53aa1a",
        "collapsed": true,
        "_cell_guid": "1cd8bd26-540b-4887-812f-ff2ae79da3b1",
        "trusted": false
      },
      "cell_type": "code",
      "source": "correlation_matrix = train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(correlation_matrix, vmax=.8, square=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9255a59f4f4d1366394b9fa369ce11c81a8a74f8",
        "_cell_guid": "0f6a651d-728c-4721-8173-61c12e57492c"
      },
      "cell_type": "markdown",
      "source": "Let's select the numericMostCorr from the heatmap indicating the features that are highly correlated to target variable"
    },
    {
      "metadata": {
        "_uuid": "c10c94d5a7f0f2091f0a9216341843c7f7ead476",
        "collapsed": true,
        "_cell_guid": "7d8903db-4668-4ea0-b309-179597a203c6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#data exploration to find SalePrice relation to some important numeric variables\n\nnumeric = [feature for feature in train.columns if train.dtypes[feature] != 'object']\nnumeric.remove('Id')\nnumreicMostCorr = ['LotFrontage', 'OverallQual', 'YearBuilt', 'YearRemodAdd', '1stFlrSF', '2ndFlrSF', 'TotalBsmtSF', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'GarageArea', 'GarageCars']\n\nfor feature in numreicMostCorr:\n    featureDF = pd.concat([train['SalePrice'], train[feature]], axis=1)\n    featureDF.plot.scatter(x=feature, y='SalePrice', ylim=(0,800000))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "518b36dd1c82ea40d225b82a7d34229830acc2b1",
        "_cell_guid": "98dddcdf-849e-49d0-b738-75080978134d"
      },
      "cell_type": "markdown",
      "source": "Identify the relation between the selected features"
    },
    {
      "metadata": {
        "_uuid": "bed065458293c44c9aedb2ea9fbc448478398c4d",
        "collapsed": true,
        "_cell_guid": "abded99e-b4c2-46a6-9d49-f98025e6b617",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#High correlation between some features themselves. So, we can choose anyone of the pair\n\npairs = [('GarageArea', 'GarageCars'), \n         ('YearBuilt', 'YearRemodAdd'), \n         ('TotalBsmtSF', 'TotRmsAbvGrd'),\n         ('GrLivArea', 'FullBath'),\n         ('TotalBsmtSF', '1stFlrSF'),\n         ('GrLivArea', '2ndFlrSF')\n        ]\n\nfor pair in pairs:\n    featureDF = pd.concat([train[pair[0]], train[pair[1]]], axis=1)\n    featureDF.plot.scatter(x=pair[0], y=pair[1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "57514e1378f78ed5e33604150a4dc3378947c3a8",
        "_cell_guid": "be9f3aac-5a1a-40b8-97b7-856ded288ef9"
      },
      "cell_type": "markdown",
      "source": "Select the categorical features and see the relationship with target variable"
    },
    {
      "metadata": {
        "_uuid": "48dac905206312aa127c6868f0e4955cfd253ca9",
        "collapsed": true,
        "_cell_guid": "c6b48858-a982-4b3e-8242-aa3418518c67",
        "trusted": false
      },
      "cell_type": "code",
      "source": "categorical = [feature for feature in train.columns if train.dtypes[feature] == 'object']\nfor category in categorical:\n    data = pd.concat([train[category], train['SalePrice']], axis=1)\n    data[category] = data[category].astype('category')\n    if data[category].isnull().any():\n        data[category] = data[category].cat.add_categories(['MISSING'])\n        data[category] = data[category].fillna('MISSING')\n    cat_data = pd.concat([data['SalePrice'], data[category]], axis=1)\n    f, ax = plt.subplots(figsize=(8, 6))\n    fig = sns.boxplot(x=category, y=\"SalePrice\", data=cat_data)\n    fig.axis(ymin=0, ymax=800000)\n    plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa935bdfe3af2014002b5a9e190a894bd3ee645b",
        "_cell_guid": "ae58d197-dbb6-492e-9e07-6ab8db79c3b0"
      },
      "cell_type": "markdown",
      "source": "Let's delete the missing data with more than 30% and also delete the highly correlated features"
    },
    {
      "metadata": {
        "_uuid": "24c3dc6fc888e4885ff25f5a60ab4168b981e77b",
        "collapsed": true,
        "_cell_guid": "e3ec994b-d66d-444e-ab6d-a4fb11c5fdb6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def removeFromList(sourceList, filterList):\n    filteredList = list(filter(lambda x: x not in filterList, sourceList))\n    return filteredList\n\ndef process_missing(df, numreicCorr, categoricalC):\n    numeric_h_correlated = ['GarageCars', '1stFlrSF', '2ndFlrSF', 'YearRemodAdd', 'FullBath']\n    categorical_h_correlated = ['Alley', \n                                               'LotShape', \n                                               'LandSlope', \n                                               'BldgType', \n                                               'Exterior1st',\n                                               'Exterior2nd',\n                                               'ExterCond',\n                                               'BsmtCond',\n                                               'BsmtExposure',\n                                               'BsmtFinType1',\n                                               'BsmtFinType2',\n                                               'HeatingQC',\n                                               'GarageFinish',\n                                               'GarageType',\n                                               'GarageCond',\n                                               'Fence'\n                                              ]\n    #missing data\n    numeric_missing = df[numreicCorr].isnull().sum().sort_values(ascending=False)\n    categorical_missing = df[categoricalC].isnull().sum().sort_values(ascending=False)\n    \n    #delete missing data that's more than 30% percent\n    numeric_to_delete = (numeric_missing[numeric_missing > 438]).index\n    categorical_to_delete = (categorical_missing[categorical_missing > 438]).index\n\n    numreicCorr = removeFromList(numreicCorr, numeric_to_delete)\n    categoricalC = removeFromList(categoricalC, categorical_to_delete)\n\n    #delete highly correlated numeric features\n    numreicCorr = removeFromList(numreicCorr, numeric_h_correlated)\n    categoricalC = removeFromList(categoricalC, categorical_h_correlated)\n    \n    return (df, numreicCorr, categoricalC)\n\ntrain, numericMostCorr_train, categorical_train = process_missing(train, numreicMostCorr, categorical)\nholdout, numericMostCorr_holdout, categorical_holdout = process_missing(holdout, numreicMostCorr, categorical)\n\nall_columns = numericMostCorr_train + categorical_train + ['SalePrice']\ntrain = train[all_columns]\n\nholdoutids = holdout.Id\nholdout = holdout[numericMostCorr_holdout + categorical_holdout]\n\nprint(train.columns.values)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "eb776719bc2d6a74b6ef6e7dbe64e116fd58eca7",
        "_cell_guid": "b351c9a0-9d10-4f60-a4d5-a87229657adc"
      },
      "cell_type": "markdown",
      "source": "Fill the missing/na features"
    },
    {
      "metadata": {
        "_uuid": "25d671019db4c0ea1b028de451cd7d49220da218",
        "_cell_guid": "442ba00c-1192-4647-a70a-ae43d3e93975"
      },
      "cell_type": "markdown",
      "source": "For the rest of missing values, fill them with their mean / word 'Missing'"
    },
    {
      "metadata": {
        "_uuid": "1b1849be84d0b4d8f506313b7394f976cd844e65",
        "collapsed": true,
        "_cell_guid": "9ded9623-781d-443b-b70f-9f37baa65ca2",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\ndef process_na(df):\n    #handle numeric n/a\n    df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].mean())\n    #df[numreicMostCorr].isnull().sum().sort_values(ascending=False)\n\n    #handle categorical n/a\n    df['BsmtQual'] = df['BsmtQual'].fillna(\"Missing\")\n    df['GarageQual'] = df['GarageQual'].fillna(\"Missing\")\n    df['MasVnrType'] = df['MasVnrType'].fillna(\"Missing\")\n    df = df.drop(df.loc[df['Electrical'].isnull()].index)\n    return df\n\n    #train[categorical].isnull().sum().sort_values(ascending=False)\n\ntrain = process_na(train)\nholdout = process_na(holdout)\n\ntrain.head(5)\n\n\nholdout[numericMostCorr_holdout].isnull().sum().sort_values(ascending=False)\nholdout['GarageArea'] = holdout['GarageArea'].fillna(holdout['GarageArea'].mean())\nholdout['TotalBsmtSF'] = holdout['TotalBsmtSF'].fillna(holdout['TotalBsmtSF'].mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "29cf24deafaa7f821ea49fefd86c0619bad55189",
        "_cell_guid": "9ec149f3-5c33-4a96-8624-894883f79c6a"
      },
      "cell_type": "markdown",
      "source": "**Now, if we examine the numeric features like Sale Price, etc, we notice that some are skewed.**"
    },
    {
      "metadata": {
        "_uuid": "cecda27595b1599bb85cf017bb95890d90e4ff62",
        "collapsed": true,
        "_cell_guid": "2fa8672d-adba-448b-9f7b-d70d8280622d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#skewed saleprice\nsaleprice = pd.DataFrame({\"saleprice_skewed\" :train['SalePrice']})\nsaleprice.hist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "49f1618e081c372e2afd647d38bf9237b5dd38f6",
        "collapsed": true,
        "_cell_guid": "2ac690d3-6555-420d-b37f-9abb8d37d7fe",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#handle numeric skewness\nfrom scipy.stats import skew\ndef process_skewness(df, numericCorr, isholdout=False):\n    if isholdout:\n        skewed_cols = numericCorr\n    else:\n        skewed_cols = numericCorr + ['SalePrice']\n    skewed = df[skewed_cols].apply(lambda x: skew(x.dropna()))\n    skewed = skewed[skewed > 0.75]\n    skewed = skewed.index\n    df[skewed] = np.log1p(df[skewed])\n    return (df,skewed_cols)\n\ntrain, skewed_cols_train = process_skewness(train, numericMostCorr_train)\nholdout, skewed_cols_holdout = process_skewness(holdout, numericMostCorr_holdout, True)\n\nfor numer in skewed_cols_train:\n    numerFeature = pd.DataFrame({\"unskewed_\"+numer:train[numer]})\n    numerFeature.hist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "854b0c4fce6c4c2c24f1f952c5abf7c8be23e686",
        "_cell_guid": "f71ed8fe-9fee-482b-9bfe-49b8dca6f18b"
      },
      "cell_type": "markdown",
      "source": "Generate dummies for labels"
    },
    {
      "metadata": {
        "_uuid": "e0399f36dee4ed95ae59b72b823e09ce55523911",
        "collapsed": true,
        "_cell_guid": "dbbeb897-526c-4db5-9ac5-fb374867aa33",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#create dummies for categorical features\ndef get_dummies(df):\n    return pd.get_dummies(df)\n\nall_data = pd.concat((train.loc[:,'LotFrontage':'SaleCondition'],\n                      holdout.loc[:,'LotFrontage':'SaleCondition']))\nall_data = get_dummies(all_data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1a2000c18eb26fecf12aaf4ea8ab2e6be806f281",
        "_cell_guid": "61172c9e-ef5b-46f2-8a3a-d6bb156f0ef9"
      },
      "cell_type": "markdown",
      "source": "Train a RandomForestRegressor to estimate the houseprices "
    },
    {
      "metadata": {
        "_uuid": "b9080cbbd6fd0db149063b34f2aaebaa3073fa63",
        "collapsed": true,
        "_cell_guid": "802a358a-4ef6-40db-a7ce-02157acc166d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.linear_model import LassoLarsCV\n\ny = train.SalePrice\nX = all_data[:train.shape[0]]\nholdout_X = all_data[train.shape[0]:]\n\nregressor = RandomForestRegressor(n_estimators = 150, random_state = 0)\n\nregressor.fit(X, y)\n\npreds = np.expm1(regressor.predict(holdout_X))\n\nsolution = pd.DataFrame({\"id\":holdoutids, \"SalePrice\":preds})\nsolution.to_csv(\"HousePrice.csv\", index = False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "name": "python",
      "version": "3.6.3",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}